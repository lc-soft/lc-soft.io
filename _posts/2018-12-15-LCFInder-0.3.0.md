---
title: LC-Finder 0.3.0 Beta 开发日志
repo: lc-soft/LC-Finder
milestone: 5
---
## 2019-01-12
darknet 在处理错误时是调用 exit() 退出的，一个图形界面程序在出错时直接闪退会影响用户体验，用户都看不到错误信息，不利于排查问题，需要改造 darknet 的错误处理方式。以前在添加 png 图片读取功能时有了解到 setjmp()，可以用它实现，但感觉直接调用不太方便，于是搜索到了这篇文章《[Exceptions in C with Longjmp and Setjmp](http://www.di.unipi.it/~nids/docs/longjump_try_trow_catch.html)》，可以用宏定义来包装一下 setjmp() 和 longjmp()。

darknet 的错误处理已调整，现在 LCFinder 可以捕获到它的错误并输出到界面上，效果如下：

[![LCFinder detector error](/static/images/devlog/20190112202427.png "LCFinder detector error")](/static/images/devlog/20190112202427.png)

## 2019-01-06

图片检测功能已经完成，测试时内存占用 1.6GB 以上，测了几次后会出现 "no CUDA-capable device is detected" 错误，无法继续使用。

CUDA 和 cuDNN 库的体积很大，加起来有 400 MB 以上，再算上一些预训练模型文件话，占用空间近 1 GB，这以后就不能宣称“轻量级”的工具了，等发布时需要考虑把文件拆分开来下载，比如拆分成：基础版 + GPU 加速版 + 检测器配置文件。

## 2019-01-03

配置文件里的文件路径是相对于当前工作目录的，如果把它们放到自定义目录里的话会找不到配置里指定的文件，有两个解决方案：

- 使用检测器前，重置配置文件里记录的文件路径，改为绝对路径
- 添加代码，在读取完配置文件后，修改里面的文件路径

## 2019-01-02

准备添加识别功能，darknet 的文档里有给出现成的配置文件和预训练好的模型，可以直接拿来用，接下来需要考虑该如何存放和读写这些文件，“设置”界面还需要给个下拉框让用户选择。

现在的训练就一个开始和结束操作，没其它可配置的，假如用户只想拿某个文件夹内的图片给检测器训练，该如何处理？

## 2019-01-01

决定将检测器的设置项放到“设置”界面里。

识别和训练任务在开始后，需要显示当前进度、剩余时间，任务的操作只有开始和停止，暂不添加暂停功能。

## 2018-12-31

需要一个界面来控制检测器的识别和训练任务，还要能切换和新建配置文件，把这些配置项全放到“设置”里的话感觉有点不太适。

## 2018-12-30

粗略的看了下 darknet 的代码，感觉比较乱，部分核心功能模块里还夹杂了一些命令行交互的代码，不适合直接当成函数库来调用。考虑到 LCFinder 在训练时需要显示进度，而 darknet 没有直接提供相关接口，因此决定自己动手改代码。直接改源代码的话，以后合并上游代码比较麻烦，可以写个封装库，重新定义一些接口，接口命名风格参考 [levedb/c.h](https://github.com/google/leveldb/blob/master/include/leveldb/c.h)。

编译了个无 GPU 加速的版本，识别一张图要 80 多秒，挺慢的，改用带 GPU 加速的版本后耗时只需 0.06 秒，这提升挺大的。

## 2018-12-23

已完成图片区域标记功能，界面细节有待继续改进，也发现了 LCUI 的几个 bug，接下来需要考虑数据存储策略和 darknet 的调用方式。

[![LCFinder label boxes](/static/images/devlog/20181223221409.png "LCFinder label boxes")](/static/images/devlog/20181223221409.png)

## 2018-12-22

标签框模块需要的数据有：文件路径、图片所处的容器、图片焦点坐标、浏览区域的偏移量，可以定义个结构体装载这些数据，然后在图片查看器的数据变化时将这些数据传给它。

图片中标记区域需要存储到文件里，可选的文件位置有两个：

- 和图片文件放在同一位置，也就是同名、同目录、不同后缀。好处是可以和文件一起移动，不受系统重装、LCFinder 数据被删除等情况的影响。坏处是训练模型时遍历文件比较麻烦，不好导出数据放到其它环境下重新训练，而且 UWP 版本的文件操作受到限制，需要另外再实现文件读写功能。
- 放到用户主目录下。好处是数据文件比较集中，文件遍历方便。

## 2018-12-17

标记框已经完成，接下来是添加标记面板，然后将标记功能整合到图片查看器。标记面板需要展示已标记的区域信息列表和可添加的标记列表，实现起来比较简单，复杂的是后者，在图片切换时需要重置标记区域，缩放和移动图片浏览区域时需要更新标记框的位置和尺寸，两个功能模块的数据通信有些让人纠结。

## 2018-12-15

准备添加图像识别功能。之前有了解过 [TensorFlow](https://github.com/tensorflow/tensorflow)，它有提供 C、C++ 接口，也有现成的用 C++ 实现的[图片识别示例](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/label_image)，本打算将这个示例改用 C 接口实现然后给 LCFinder 调用，但看了 C 接口和相关资料后觉得很麻烦，比如 [TF_SessionRun()](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.h#L1393-L1430) 的参数需要什么内容，这些内容表示什么，怎么生成？无脑复制粘贴相关代码再凭感觉改会让人有点迷茫，在写代码前还是先了解 TensorFlow 的工作原理和相关示例代码好些。

现在打算用 [yolo](https://pjreddie.com/darknet/yolo/) 来实现图像识别功能，官方示例的效果能够标记出图片中的对象和名称，正好符合需求。

[![yolo example](https://pjreddie.com/media/image/Screen_Shot_2018-03-24_at_10.48.42_PM.png "yolo example")](https://pjreddie.com/media/image/Screen_Shot_2018-03-24_at_10.48.42_PM.png)

在添加图像识别功能之前需要给 LCFinder 加上区域标记功能，能够像 [Yolo_mark](https://github.com/AlexeyAB/Yolo_mark) 一样标记图片中各个对象的边界框并输出到文件，以便使用 darknet 训练 yolo 模型。

[![yolo mark](https://camo.githubusercontent.com/e1e33a7ef92dfc86ab8929dd0e8e96395cbcab5c/68747470733a2f2f686162726173746f726167652e6f72672f66696c65732f3232392f6630362f3237372f32323966303632373766636334393237393334326237656466616262623437612e6a7067 "yolo mark")](https://camo.githubusercontent.com/e1e33a7ef92dfc86ab8929dd0e8e96395cbcab5c/68747470733a2f2f686162726173746f726167652e6f72672f66696c65732f3232392f6630362f3237372f32323966303632373766636334393237393334326237656466616262623437612e6a7067)

LCFinder 的图片查看器是把图片当成背景图来呈现的，不是一个单独的部件，如何定位已标记的边界框并根据缩放比例调整它的尺寸？

标记框要做成四边+四角可拖动调整尺寸的话有点麻烦，简单点，只允许点击拖动右下角来调整框的尺寸。